{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = [[\"hello\", \"world\"], ['I', \"am\", \"muqi\"]]\n",
    "max(len(sent) for sent in sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(len(sent) for sent in sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(num_embeddings=10, embedding_dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0502,  0.9442,  0.1887],\n",
       "         [ 0.4046,  0.5226,  1.3767],\n",
       "         [ 0.9331,  0.8740, -0.3424],\n",
       "         [-0.0202, -1.5035, -0.9274]],\n",
       "\n",
       "        [[ 0.9331,  0.8740, -0.3424],\n",
       "         [ 0.0793,  1.2880,  1.1666],\n",
       "         [ 0.4046,  0.5226,  1.3767],\n",
       "         [ 0.6238,  0.3612,  0.6272]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.LongTensor([[1, 2, 4, 5], [4, 3, 2, 9]])\n",
    "embedding(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [-1.2526,  2.5538, -0.6651],\n",
       "        [ 0.2548,  0.1436,  1.3404]], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of changing `pad` vector\n",
    "padding_idx = 0\n",
    "embedding = nn.Embedding(3, 3, padding_idx=padding_idx)\n",
    "embedding.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8821, 0.3777, 0.8630],\n",
       "        [0.9137, 0.9933, 0.9808]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand((2, 3))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.4153e-02, -5.0768e-01,  4.0820e-04, -3.7730e-01],\n",
       "        [ 2.0532e-01, -8.1654e-01, -2.3987e-01, -5.6550e-01]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(3, 4, bias=False)\n",
    "linear(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0325,  0.3205, -0.1455],\n",
      "        [-0.1602, -0.4499, -0.2276],\n",
      "        [-0.0704, -0.4372,  0.2638],\n",
      "        [-0.0312, -0.2472, -0.2971]])\n"
     ]
    }
   ],
   "source": [
    "print(linear.weight.detach())\n",
    "weight = linear.weight.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0325,  0.3205, -0.1455],\n",
       "        [-0.1602, -0.4499, -0.2276],\n",
       "        [-0.0704, -0.4372,  0.2638],\n",
       "        [-0.0312, -0.2472, -0.2971]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.4153e-02, -5.0768e-01,  4.0820e-04, -3.7730e-01],\n",
       "        [ 2.0532e-01, -8.1654e-01, -2.3987e-01, -5.6550e-01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X @ weight.T "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5063, -1.1010, -0.7137],\n",
       "         [-1.2072, -0.8427,  0.3872],\n",
       "         [ 0.4957, -0.0050, -1.0101],\n",
       "         [ 0.8605,  0.1032, -1.0073]],\n",
       "\n",
       "        [[-0.5147, -1.6275,  1.5635],\n",
       "         [-0.3027, -0.2740,  0.2348],\n",
       "         [-0.2201,  0.1086, -0.9181],\n",
       "         [-1.1419,  0.3980,  2.7141]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(2, 4, 3)  # src_len, batch_size:4, embedding_size=3\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = nn.LSTM(input_size=3, hidden_size=5)\n",
    "output, (h_n, c_n) = l(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_n.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_n.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(10, 20, 2) # input_size: 10, hidden_size: 20, num_layer:2\n",
    "input = torch.randn(5, 3, 10) # src_len: 5, batch_size: 3, embedding_size: 10\n",
    "h0 = torch.randn(2, 3, 20) # hidden_0:    num_layer: 2, batch_size: 3, hidden_size: 20\n",
    "c0 = torch.randn(2, 3, 20) # cell_0:      num_layer: 2,  batch_size: 3, hidden_size: 20 \n",
    "output, (hn, cn) = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 20])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0062,  0.0136, -0.0759, -0.1136,  0.1852, -0.1495, -0.0032,\n",
       "          -0.0247, -0.0405,  0.1370, -0.2255,  0.0016, -0.0061, -0.0519,\n",
       "           0.0878,  0.0337, -0.1171, -0.1153, -0.1839,  0.0550],\n",
       "         [-0.1818,  0.0722,  0.1015, -0.0086,  0.0442, -0.0272, -0.1977,\n",
       "           0.2624, -0.2884,  0.0169, -0.0990,  0.1516,  0.1033, -0.0417,\n",
       "           0.0384, -0.1157, -0.1025,  0.0223, -0.1434, -0.0367],\n",
       "         [-0.1348,  0.0634,  0.0910,  0.1521,  0.0169,  0.0596, -0.1282,\n",
       "           0.0133, -0.1792,  0.1265, -0.1825, -0.1965,  0.1333,  0.0229,\n",
       "          -0.0358, -0.0789,  0.0693, -0.1640, -0.1281,  0.1161]],\n",
       "\n",
       "        [[-0.0244, -0.0013,  0.0169, -0.1830,  0.0003, -0.0704,  0.0325,\n",
       "           0.0555,  0.0314, -0.1814,  0.0027, -0.0783, -0.0754, -0.0080,\n",
       "           0.1075,  0.0710, -0.0468, -0.0831,  0.0903,  0.0456],\n",
       "         [ 0.0059,  0.0487,  0.0209, -0.2704,  0.0442, -0.1275, -0.0824,\n",
       "          -0.0486,  0.0267, -0.2158,  0.0730, -0.0536, -0.0588, -0.0502,\n",
       "           0.0935,  0.1407, -0.0262, -0.1319,  0.0674,  0.1837],\n",
       "         [ 0.0159,  0.0118,  0.0054, -0.1177,  0.0532, -0.0832,  0.1206,\n",
       "           0.0072,  0.0082, -0.0590,  0.0161, -0.0800, -0.0453, -0.0315,\n",
       "           0.1300,  0.0929,  0.0320, -0.0527,  0.1259,  0.0834]]],\n",
       "       grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 20])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 20])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rnn.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence,pack_padded_sequence,pack_sequence,pad_packed_sequence\n",
    "\n",
    "class MyData(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def collate_fn(data):\n",
    "    data.sort(key=lambda x: len(x), reverse=True)\n",
    "    data = pad_sequence(data, batch_first=True, padding_value=0)\n",
    "    return data\n",
    "\n",
    "a = torch.tensor([1,2,3,4])\n",
    "b = torch.tensor([5,6,7])\n",
    "c = torch.tensor([7,8])\n",
    "d = torch.tensor([9])\n",
    "train_x = [a, b, c, d]\n",
    "\n",
    "data = MyData(train_x)\n",
    "data_loader = DataLoader(data, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "# 采用默认的 collate_fn 会报错\n",
    "#data_loader = DataLoader(data, batch_size=2, shuffle=True) \n",
    "# batch_x = iter(data_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4],\n",
      "        [7, 8, 0, 0]])\n",
      "tensor([[5, 6, 7],\n",
      "        [9, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "for x in data_loader:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    data.sort(key=lambda x: len(x), reverse=True)\n",
    "    seq_len = [s.size(0) for s in data] # 获取数据真实的长度\n",
    "    data = pad_sequence(data, batch_first=True)    \n",
    "    data = pack_padded_sequence(data, seq_len, batch_first=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.3764e-02, -1.9899e+00,  5.2987e-01],\n",
       "         [ 1.8881e+00,  3.5205e-01, -1.8764e-01]],\n",
       "\n",
       "        [[-1.4849e+00,  1.0719e-01, -3.0231e+00],\n",
       "         [-1.8021e+00, -3.2364e-01, -4.2887e-01]],\n",
       "\n",
       "        [[ 1.6430e+00, -4.6612e-01, -1.2152e-01],\n",
       "         [ 6.5978e-01,  6.2439e-01, -1.3417e+00]],\n",
       "\n",
       "        [[ 1.0185e+00,  1.0280e+00,  1.4772e+00],\n",
       "         [-1.5829e+00,  1.0082e+00,  7.3375e-01]],\n",
       "\n",
       "        [[ 1.1040e+00, -8.3155e-01, -1.2767e-01],\n",
       "         [-8.6767e-01, -4.5987e-01, -2.2826e+00]],\n",
       "\n",
       "        [[ 9.5114e-01,  1.5636e+00, -4.6500e-01],\n",
       "         [ 1.9530e-01,  7.6213e-01,  9.1524e-01]],\n",
       "\n",
       "        [[-7.2296e-01,  2.5964e-01, -2.7762e+00],\n",
       "         [-2.4087e-03, -2.6460e-01,  2.2495e-01]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn((7, 2, 3)) # src_len, batch_size, embeding_size\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 0.0538, -1.9899,  0.5299],\n",
       "        [ 1.8881,  0.3520, -0.1876],\n",
       "        [-1.4849,  0.1072, -3.0231],\n",
       "        [-1.8021, -0.3236, -0.4289],\n",
       "        [ 1.6430, -0.4661, -0.1215],\n",
       "        [ 1.0185,  1.0280,  1.4772],\n",
       "        [ 1.1040, -0.8316, -0.1277]]), batch_sizes=tensor([2, 2, 1, 1, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pack_X = pack_padded_sequence(X, [5, 2], batch_first=False) # get the true\n",
    "pack_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PackedSequence(data=tensor([[ 0.0513, -0.1216, -0.1206, -0.0626,  0.2191,  0.0462, -0.1620, -0.1192],\n",
       "         [-0.1388, -0.0696, -0.1174,  0.3243,  0.1639, -0.2015, -0.1552, -0.0157],\n",
       "         [-0.0276, -0.1672, -0.5100, -0.1163,  0.3693, -0.1052, -0.2718, -0.2799],\n",
       "         [-0.0499, -0.1091, -0.2752,  0.1658,  0.2080, -0.0085,  0.0015, -0.2020],\n",
       "         [-0.0718, -0.2435, -0.1977,  0.1779,  0.1624, -0.2799, -0.1635,  0.0482],\n",
       "         [-0.2580,  0.0138, -0.1369,  0.2754,  0.1702, -0.2720, -0.0945,  0.0573],\n",
       "         [-0.1224, -0.0945, -0.1727,  0.3547,  0.0462, -0.0785, -0.0934,  0.0103]],\n",
       "        grad_fn=<CatBackward0>), batch_sizes=tensor([2, 2, 1, 1, 1]), sorted_indices=None, unsorted_indices=None),\n",
       " tensor([[[-0.1224, -0.0945, -0.1727,  0.3547],\n",
       "          [-0.0499, -0.1091, -0.2752,  0.1658]],\n",
       " \n",
       "         [[ 0.2191,  0.0462, -0.1620, -0.1192],\n",
       "          [ 0.1639, -0.2015, -0.1552, -0.0157]]], grad_fn=<StackBackward0>),\n",
       " tensor([[[-0.3987, -0.1752, -0.5811,  0.6445],\n",
       "          [-0.0801, -0.2524, -0.5544,  0.3013]],\n",
       " \n",
       "         [[ 0.5695,  0.0819, -0.2744, -0.4835],\n",
       "          [ 0.2164, -0.3530, -0.2557, -0.0621]]], grad_fn=<StackBackward0>))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = nn.LSTM(input_size=3, hidden_size=4, bidirectional=True)\n",
    "encoded_X, (h, c) = l(pack_X)\n",
    "encoded_X, h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1224, -0.0945, -0.1727,  0.3547],\n",
       "         [-0.0499, -0.1091, -0.2752,  0.1658]],\n",
       "\n",
       "        [[ 0.2191,  0.0462, -0.1620, -0.1192],\n",
       "         [ 0.1639, -0.2015, -0.1552, -0.0157]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 8])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_hidden_states = pad_packed_sequence(encoded_X)[0]\n",
    "all_hidden_states.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 8])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_hidden_states.permute(1, 0, 2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1230, -0.0275, -0.1606, -0.1191, -0.1678, -0.0920,  0.0081, -0.1939],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_hidden_states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 4])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 0],\n",
      "        [3, 0, 0],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "seq = torch.tensor([[1, 2, 0], [3, 0, 0], [4, 5, 6]])\n",
    "# seq = nn.Embedding(7, 3)(seq)\n",
    "print(seq)\n",
    "lens = [2, 1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([4, 1, 3, 5, 2, 6]), batch_sizes=tensor([3, 2, 1]), sorted_indices=tensor([2, 0, 1]), unsorted_indices=tensor([1, 2, 0]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed = pack_padded_sequence(seq, lens, batch_first=True, enforce_sorted=False)\n",
    "packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_unpacked, lens_unpacked = pad_packed_sequence(packed, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 0],\n",
       "        [3, 0, 0],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_unpacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens_unpacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch.permute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(24).reshape((2, 3, 4))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [12, 13, 14, 15]],\n",
       "\n",
       "        [[ 4,  5,  6,  7],\n",
       "         [16, 17, 18, 19]],\n",
       "\n",
       "        [[ 8,  9, 10, 11],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.permute(1, 0, 2)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\TyporaWorkspace\\CS224n_NLP\\assignments\\a4\\test.ipynb Cell 44\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/TyporaWorkspace/CS224n_NLP/assignments/a4/test.ipynb#X61sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m hidden_size \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/TyporaWorkspace/CS224n_NLP/assignments/a4/test.ipynb#X61sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m src_length \u001b[39m=\u001b[39m [\u001b[39m3\u001b[39m, \u001b[39m2\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/TyporaWorkspace/CS224n_NLP/assignments/a4/test.ipynb#X61sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m torch\u001b[39m.\u001b[39mmanual_seed(\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/TyporaWorkspace/CS224n_NLP/assignments/a4/test.ipynb#X61sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m X \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn((src_len, batch_size, embedding_size))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/TyporaWorkspace/CS224n_NLP/assignments/a4/test.ipynb#X61sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m X\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "src_len: 3\n",
    "batch_size: 2\n",
    "embedding_size: 5\n",
    "\"\"\"\n",
    "src_len = 3\n",
    "batch_size = 2\n",
    "embedding_size = 5\n",
    "hidden_size = 4\n",
    "\n",
    "src_length = [3, 2]\n",
    "torch.manual_seed(0)\n",
    "X = torch.randn((src_len, batch_size, embedding_size))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-1.1258, -1.1524, -0.2506, -0.4339,  0.8487],\n",
       "        [ 0.6920, -0.3160, -2.1152,  0.3223, -1.2633],\n",
       "        [ 0.3500,  0.3081,  0.1198,  1.2377, -0.1435],\n",
       "        [-0.1116, -0.6136,  0.0316, -0.4927,  0.2484],\n",
       "        [ 0.4397,  0.1124, -0.8411, -2.3160, -0.1023]]), batch_sizes=tensor([2, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_X = pack_padded_sequence(X, src_length)\n",
    "packed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 0.0872, -0.0503, -0.0445,  0.0584, -0.2065, -0.4339,  0.2128,  0.0675],\n",
       "        [-0.2401, -0.0077, -0.0171,  0.1581, -0.2012, -0.2448,  0.0195,  0.0094],\n",
       "        [-0.1306, -0.1658, -0.1099, -0.1172, -0.1101, -0.0958, -0.0525, -0.0151],\n",
       "        [-0.0590,  0.0121, -0.0462,  0.1905, -0.1235, -0.2117,  0.1316,  0.0339],\n",
       "        [ 0.0397,  0.0602,  0.0749,  0.1196, -0.0026,  0.0642,  0.3751, -0.0356]],\n",
       "       grad_fn=<CatBackward0>), batch_sizes=tensor([2, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoder = nn.LSTM(input_size=embedding_size, hidden_size=hidden_size, bidirectional=True)\n",
    "encoded_X, (h_n, c_n) = Encoder(packed_X)\n",
    "encoded_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0397,  0.0602,  0.0749,  0.1196],\n",
       "         [-0.0590,  0.0121, -0.0462,  0.1905]],\n",
       "\n",
       "        [[-0.2065, -0.4339,  0.2128,  0.0675],\n",
       "         [-0.2012, -0.2448,  0.0195,  0.0094]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hidden state\n",
    "h_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0922,  0.4373,  0.2559,  0.1399],\n",
       "         [-0.1037,  0.0438, -0.1153,  0.2507]],\n",
       "\n",
       "        [[-0.5648, -0.6973,  0.2884,  0.1231],\n",
       "         [-0.5228, -0.4113,  0.0305,  0.0225]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell state\n",
    "c_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0550, -0.4747,  0.0579, -0.2680,  0.4750, -0.5831,  0.6619, -0.1194],\n",
       "        [ 0.0046, -0.3216,  0.2925, -0.1548,  0.1405, -0.6188,  0.2519, -0.1294]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((c_n[0], c_n[1]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0350, -0.0484,  0.2423,  0.0347,  0.2130, -0.2706,  0.1727,\n",
       "           -0.0421],\n",
       "          [ 0.1740, -0.2226, -0.0306, -0.2359,  0.1024, -0.2922,  0.1648,\n",
       "           -0.0897]],\n",
       " \n",
       "         [[-0.2315, -0.2480,  0.2309,  0.0017,  0.1913, -0.1477,  0.2213,\n",
       "           -0.0290],\n",
       "          [ 0.0033, -0.1685,  0.1233, -0.0630,  0.1705, -0.2066,  0.1172,\n",
       "           -0.0117]],\n",
       " \n",
       "         [[ 0.0413, -0.1580,  0.0086, -0.1854,  0.3150, -0.2815,  0.0363,\n",
       "           -0.0552],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]]], grad_fn=<CopySlices>),\n",
       " tensor([3, 2]))"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens = pad_packed_sequence(encoded_X)\n",
    "enc_hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0350, -0.0484,  0.2423,  0.0347,  0.2130, -0.2706,  0.1727,\n",
       "          -0.0421],\n",
       "         [-0.2315, -0.2480,  0.2309,  0.0017,  0.1913, -0.1477,  0.2213,\n",
       "          -0.0290],\n",
       "         [ 0.0413, -0.1580,  0.0086, -0.1854,  0.3150, -0.2815,  0.0363,\n",
       "          -0.0552]],\n",
       "\n",
       "        [[ 0.1740, -0.2226, -0.0306, -0.2359,  0.1024, -0.2922,  0.1648,\n",
       "          -0.0897],\n",
       "         [ 0.0033, -0.1685,  0.1233, -0.0630,  0.1705, -0.2066,  0.1172,\n",
       "          -0.0117],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000]]], grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens[0].permute(1, 0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch.split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4802, -0.0287,  1.3481],\n",
       "        [-1.8695,  0.2533,  1.4783],\n",
       "        [ 0.9611, -1.1104, -0.2056],\n",
       "        [-0.4674,  0.3604,  0.2584]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(4, 3)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.4802, -0.0287,  1.3481]]),\n",
       " tensor([[-1.8695,  0.2533,  1.4783]]),\n",
       " tensor([[ 0.9611, -1.1104, -0.2056]]),\n",
       " tensor([[-0.4674,  0.3604,  0.2584]]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(X, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
